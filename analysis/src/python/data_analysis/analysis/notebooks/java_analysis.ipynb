{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperskill java dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Dict\n",
    "import string\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = ['easy', 'medium', 'hard']\n",
    "difficulty_palette=dict(easy=(0.98, 0.73, 0.62), medium=(0.98, 0.41, 0.28), hard=(0.79, 0.09, 0.11))\n",
    "complexity = ['shallow', 'middle', 'deep']\n",
    "complexity_palette=dict(shallow=(0.77, 0.85, 0.93), middle=(0.41, 0.68, 0.83), deep=(0.12, 0.44, 0.70))\n",
    "level = ['low', 'avg', 'high']\n",
    "level_palette=dict(low=(0.77, 0.91, 0.75), avg=(0.45, 0.76, 0.46), high=(0.13, 0.54, 0.26))\n",
    "client = ['idea', 'web']\n",
    "client_palette=dict(idea=(0.52, 0.18, 0.44), web=(0.44, 0.49, 0.69))\n",
    "template = [True, False]\n",
    "template_palette={True: (0.79, 0.09, 0.11), False: (0.0, 0.0, 0.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy -> medium -> hard\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxElEQVR4nO3XP0rEQACF8Zfo2MSA4LIHsIh4I0srb+AZLPQgXmmDJ9hKXKdxMGPlnwWDgs4OPr5fOWle8RFmmpxzFmCkrT0A+GtEDTtEDTtEDTv7cx+maVKMUSEENU2zy03At3LOSimp6zq17fa/eTbqGKPGcSw+DviNYRjU9/3W2WzUIQRJ0snjvcKUyi6rZHV0ptO7m9ozilmdX+nl4rL2jDIWx9q7vX7v9LPZqN+uHGFKOjCNWpIOnh5qTyhrva69oKivrsY8FGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGGHqGFnf+5DzlmSlNqwszE1PB8e1Z5Q1nJZe0EZi2NJH51+1uSvTiVtNhuN41h2GPBLwzCo7/uts9mop2lSjFEhBDVNs5OBwE/lnJVSUtd1atvtW/Rs1MB/xUMRdogadogadogadl4BtaZPyWJbj3wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow -> middle -> deep\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxklEQVR4nO3XMU7DMBSH8We3BtSQqUJiYM5VuAI34CachY37ZO6CGIuRIDSPoVLViFoMJY361/ebIjuR3vDJcoK7uwFC4tQDAP+NqCGHqCGHqCFnXtro+95yzpZSshDCKWcC/uTu1nWdVVVlMQ7P5mLUOWdr23b04YBjNE1jdV0P1opRp5TMzOzz6tYsFl87a5cfK3teXUw9xmge7r7s8eV16jFGsVxEe7q/2XW6r1jr7soR5+bx94cq3jfaV6u3vJl6hFEduhrzowg5RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA05RA0589KGu28f+m8Lp5pmAtczn3qEUd1Us6lHGMVysT2Pd53uCX5o1czW67W1bTvuZMCRmqaxuq4Ha8Wo+763nLOllCwE5bMa58jdres6q6rKYhzeootRA+eKH0XIIWrIIWrIIWrI+QHBjEzJcJbx/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low -> avg -> high\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxUlEQVR4nO3YQUrDQByF8TehQ6UxFEWvkBN4DfEenkPwPOIZvEROILhwUaYokfxdCKUFgwuNoY/vtyqTzVt8hElTRIQAI9XcA4C/RtSwQ9SwQ9Swsxh7MAyDSinKOSul9J+bgB9FhPq+V13XqqrDd/No1KUUdV03+TjgN9q2VdM0B2ejUeecJUnvF0VaeP7rt3w+1cP2ce4Zk7lZXev26X7uGZM4X651d3W763TfaNS7K8ciFKZRS1KJ7dwTJvXy9jr3hEl9dzXmQxF2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2iBp2FmMPIuLrx0dS+q81M6jTau4Jk7o8OZt7wiTOl2tJe53uSfHdqaTNZqOu66ZdBvxS27ZqmubgbDTqYRhUSlHOWSk5v6txjCJCfd+rrmtV1eEtejRq4FjxoQg7RA07RA07RA07n2R+Ts4ylx+jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idea -> web\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAABECAYAAABHwoFDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABd0lEQVR4nO3dMU4CURRG4TvgRDITCit3wDK0tHZRdu7FWlfgGliAnaEgD0MmMhYGC8mLjY+nnPOV0PzkBJjuNuM4jiGcSe0BqsPwUIaHMjzUWe6N3W4XKaVo2zaapjnmJv2CcRxjGIbo+z4mk8PvdzZ8SimWy2XRcSpvsVjEfD4/eD0bvm3biIh4vnuM7WpTbllF1/e38fD0UntGEd1sGjdXl18dv8uG3/+8b1ebeHtNZdb9AWnzXntCUbm/aR/uoAwPZXgow0MZHsrwUIaHMjyU4aEMD2V4KMNDGR7K8FCGhzI8lOGhDA9leCjDQxkeyvBQhocyPJThoQwPZXgow0MZHsrwUIaHMjyU4aEMD2V4KMNDGR7K8FCGhzI8lOGhDA9leCjDQxkeyvBQhocyPJThoQwPZXio7E2a/cnZ84vuaGNq6Ltp7QlFdLPPz5U7Hdzkjgqv12vPj52A3PmxbHgPDv5vPx0czIbXafPhDsrwUIaHMjzUB3PrTJGmI9U1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(' -> '.join(difficulty))\n",
    "sns.palplot(difficulty_palette.values())\n",
    "plt.show()\n",
    "\n",
    "print(' -> '.join(complexity))\n",
    "sns.palplot(complexity_palette.values())\n",
    "plt.show()\n",
    "\n",
    "print(' -> '.join(level))\n",
    "sns.palplot(level_palette.values())\n",
    "plt.show()\n",
    "\n",
    "print(' -> '.join(client))\n",
    "sns.palplot(client_palette.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(df_left: pd.DataFrame, df_right: pd.DataFrame, left_on: str, right_on: str) -> pd.DataFrame:\n",
    "    df_merged = pd.merge(df_left, df_right, left_on=left_on, right_on=right_on, suffixes=('', '_extra'))\n",
    "    df_merged.drop(df_merged.filter(regex='_extra$').columns.tolist(), axis=1, inplace=True)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path to following csv files (or use preset default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_file_path = '../data/java/users/users.csv'\n",
    "steps_file_path = '../data/java/client/steps.csv'\n",
    "topics_file_path = '../data/java/client/topics.csv'\n",
    "\n",
    "submissions_file_path = '../data/java/result_submissions_java11.csv'\n",
    "submissions_stats_file_path = '../data/java/result_submissions_stats_java11.csv'\n",
    "\n",
    "raw_issues_stats_file_path = '../data/java/result_submissions_issues_stats_java11.csv'\n",
    "raw_issues_change_stats_file_path = '../data/java/result_submissions_issues_change_stats_java11.csv'\n",
    "qodana_issues_stats_file_path = '../data/java/qodana_issues_stats.csv'\n",
    "raw_issues_classes_file_path = '../data/java/raw_issues.csv'\n",
    "qodana_issues_classes_file_path = '../data/java/qodana_issues.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/java/result_submissions_java11.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4s/hl9y6lqs3h1c9qxxnbjmtvsr0000gn/T/ipykernel_15871/1801380130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_submissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmissions_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/java/result_submissions_java11.csv'"
     ]
    }
   ],
   "source": [
    "df_submissions = pd.read_csv(submissions_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps = pd.read_csv(steps_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOTAL_ATTEMPTS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = df_submissions[df_submissions['attempt'] == df_submissions['total_attempts']][['id', 'user_id', 'step_id', 'client', 'attempt', 'total_attempts', 'group']]\n",
    "\n",
    "d = df_last[df_last['total_attempts'] > MAX_TOTAL_ATTEMPTS].shape[0]\n",
    "s = df_last.shape[0]\n",
    "p = format(d / s * 100, '.2f')\n",
    "print(f'Filtering {d}/{s} series with <{MAX_TOTAL_ATTEMPTS} attempts ~ {p}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_template = merge_dfs(df_submissions, df_steps, left_on='step_id', right_on='id')\n",
    "\n",
    "d = df_template[df_template['template'] == True].shape[0]\n",
    "s = df_submissions.shape[0]\n",
    "p = format(d / s * 100, '.2f')\n",
    "print(f'Filtering {d}/{s} submissions with template ~ {p}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select submissions with total_attempts <= 5\n",
    "df_submissions = df_submissions[df_submissions['total_attempts'] <= MAX_TOTAL_ATTEMPTS]\n",
    "# select steps with template = True\n",
    "df_steps = df_steps[df_steps['template'] == False]\n",
    "# select submissions for steps with template = True\n",
    "df_submissions = df_submissions[df_submissions['step_id'].isin(df_steps['id'])]\n",
    "# select steps which do not present in dataset\n",
    "df_steps = df_steps[df_steps['id'].isin(df_submissions['step_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps and Topics\n",
    "**Step** - is a task where user is asked to write some code. Main attributes:\n",
    "* **id** - *identifier of step*\n",
    "* **seconds_to_complete** - *estimated secons to complete (calculated as average from all successful sumbissions)*\n",
    "* **solved_by** - *number of successful sumbissions*\n",
    "* **success_rate** - *number of successful sumbissions dvided by total number of sumbissions*\n",
    "* **topic_id** - *id of topic step is related to*\n",
    "* **complexity** - *[shallow, middle, deep] according to topic depth [d<=0.3, 0.3<d<0.6, d>=0.6]*\n",
    "* **difficulty** - *[easy, medium, hard] according to success_rate [sr<=0.33, 0.33<sr<0.66, sr>=0.66]*\n",
    "\n",
    "**Topic** - is a theme or knowledge area. Every step is related to some topic. Main attributes:\n",
    "* **id** - *identifier of step*\n",
    "* **prerequisites** - *topics ids which must be leared before*\n",
    "* **depth** - *the depth in topics tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps[['seconds_to_complete', 'solved_by', 'success_rate', 'depth']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((20, 25)), ncols=2, nrows=3)\n",
    "sns.histplot(data=df_steps, x='seconds_to_complete', ax=ax[0][0])\n",
    "sns.histplot(data=df_steps[df_steps['solved_by'] < 20000], x='solved_by', ax=ax[0][1])\n",
    "sns.histplot(data=df_steps, x='success_rate', kde=True, ax=ax[1][0])\n",
    "sns.histplot(data=df_steps, x='depth', kde=True, ax=ax[1][1])\n",
    "sns.countplot(data=df_steps, x='difficulty', ax=ax[2][0], order=difficulty, palette=difficulty_palette)\n",
    "sns.countplot(data=df_steps, x='complexity', ax=ax[2][1], order=complexity, palette=complexity_palette)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_steps.pivot_table('id', 'difficulty', 'complexity', aggfunc='count')\n",
    "corr = corr.reindex(difficulty, axis=0)\n",
    "corr = corr.reindex(complexity, axis=1)\n",
    "sns.heatmap(corr, annot=True, fmt=\"d\")\n",
    "plt.title('Steps count groped by (difficuly, complexity)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users\n",
    "\n",
    "* **id** - *identifier of user*\n",
    "* **passed_theories** - *number of passed theories steps*\n",
    "* **passed_problems** - *number of passed problems*\n",
    "* **passed_topics** - *number of passed topics*\n",
    "* **passed_stages** - *number of passed stages*\n",
    "* **passed_projects** - *number of passed projects*\n",
    "* **hypercoins** - *number of collected hypercoins*\n",
    "* **active_days** - *number of active days*\n",
    "* **max_streak** - *max streak*\n",
    "* **level** - *[low, avg, high] according to passed_topics [tp<=20, 20<tp<40, tp>=40]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(users_file_path)\n",
    "df_users = df_users[df_users['user_id'].isin(df_submissions['user_id'])]\n",
    "df_users.describe().astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((20, 20)), ncols=2, nrows=3)\n",
    "sns.histplot(data=df_users, x='passed_problems', ax=ax[0][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_users, x='passed_topics', ax=ax[0][1], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_users, x='active_days', ax=ax[1][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_users, x='hypercoins', ax=ax[1][1], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_users, x='max_streak', ax=ax[2][0], log_scale=(False, True), bins=50)\n",
    "sns.countplot(data=df_users, x='level', ax=ax[2][1], order=level, palette=level_palette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions\n",
    "Total number of submissions: 1459860\\\n",
    "Number of filtered submissions: 1411218 (without automatic resubmissions and suspicious submissions [too different from previous])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((20, 10)))\n",
    "sns.histplot(data=df_submissions, x='client', hue='base_client', multiple='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_stats = pd.read_csv(submissions_stats_file_path)\n",
    "df_submissions_stats = df_submissions_stats[df_submissions_stats['id'].isin(df_submissions['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_stats = merge_dfs(df_submissions_stats, df_submissions[['id', 'step_id', 'user_id', 'client']], left_on='id', right_on='id')\n",
    "df_submissions_stats = merge_dfs(df_submissions_stats, df_steps[['id', 'complexity', 'difficulty']], left_on='step_id', right_on='id')\n",
    "df_submissions_stats = merge_dfs(df_submissions_stats, df_users[['user_id', 'level']], left_on='user_id', right_on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_stats['raw_issues_by_code_rows'] = df_submissions_stats['raw_issues_count'] / df_submissions_stats['code_rows_count']\n",
    "df_submissions_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_stats_draw = df_submissions_stats[(df_submissions_stats['code_rows_count'] < 500) &\n",
    "                               (df_submissions_stats['code_symbols_count'] < 2000) &\n",
    "                               (df_submissions_stats['raw_issues_count'] < 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((20, 35)), ncols=2, nrows=4)\n",
    "sns.histplot(data=df_submissions_stats_draw, x='code_rows_count', ax=ax[0][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_submissions_stats_draw, x='code_symbols_count', ax=ax[0][1], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_submissions_stats_draw, x='raw_issues_count', ax=ax[1][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_submissions_stats_draw, x='qodana_issues_count', ax=ax[1][1], log_scale=(False, True), bins=50)\n",
    "\n",
    "sns.histplot(data=df_submissions_stats_draw, x='raw_issues_by_code_rows', ax=ax[2][0], log_scale=(False, True), bins=50)\n",
    "sns.countplot(data=df_submissions_stats_draw, x='level', ax=ax[2][1], order=level, palette=level_palette)\n",
    "sns.countplot(data=df_submissions_stats_draw, x='difficulty', ax=ax[3][0], order=difficulty, palette=difficulty_palette)\n",
    "sns.countplot(data=df_submissions_stats_draw, x='complexity', ax=ax[3][1], order=complexity, palette=complexity_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap_compare(df, attr_pairs, features):\n",
    "    fig, ax = plt.subplots(figsize=((20, 6 * len(attr_pairs))), \n",
    "                           ncols=len(features), nrows=len(attr_pairs), constrained_layout=True)\n",
    "    sns.set_theme(style='whitegrid', font_scale=2)\n",
    "    for i, attr_pair in enumerate(attr_pairs):\n",
    "\n",
    "        attr0, attr1 = attr_pair\n",
    "        (attr0, values0) = attr0\n",
    "        (attr1, values1) = attr1\n",
    "        for j, feature in enumerate(features):\n",
    "            axij =  ax[j] if len(attr_pairs) == 1 else ax[i][j]\n",
    "\n",
    "            if feature == 'id':\n",
    "                corr = df.pivot_table(feature, attr0, attr1, aggfunc='count')\n",
    "                axij.set_title('Submissions count') \n",
    "                fmt = 'd'\n",
    "            else:\n",
    "                corr = df.pivot_table(feature, attr0, attr1, aggfunc=np.mean)\n",
    "                axij.set_title(f'Avg {feature}') \n",
    "                fmt = '.2f'\n",
    "                \n",
    "            corr = corr.reindex(values0, axis=0)\n",
    "            corr = corr.reindex(values1, axis=1)\n",
    "            sns.heatmap(corr, annot=True, fmt=fmt, ax=axij, linewidths=.5, cmap=sns.color_palette('flare'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_submissions_stats, \n",
    "                     [(('difficulty', difficulty), ('complexity', complexity)), \n",
    "                      (('level', level), ('complexity', complexity))],\n",
    "                     ['id', 'raw_issues_count', 'raw_issues_by_code_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_submissions_stats,\n",
    "                     [(('difficulty', difficulty), ('client', client)), \n",
    "                      (('complexity', complexity), ('client', client)),\n",
    "                      (('level', level), ('client', client))],\n",
    "                     ['id', 'raw_issues_count', 'raw_issues_by_code_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_compare(df, feature: str, attrs, bins: List[int]):\n",
    "    sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "    for attr, values, palette in attrs:\n",
    "        fig, ax = plt.subplots(figsize=((20, 10)), constrained_layout=True)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('% submission')\n",
    "        for v in values:\n",
    "            df_v = df[df[attr] == v]\n",
    "            intervals = pd.cut(df_v[feature], bins=bins)\n",
    "            counts = df_v.groupby(intervals).count()['id'] / df_v.shape[0]\n",
    "            sns.lineplot(x=bins[:-1], y=counts, ax=ax, label=v, marker='o', color=palette[v])\n",
    "        ax.set_title(f'Submissions % distributions by {attr}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = [('complexity', complexity, complexity_palette), \n",
    "         ('difficulty', difficulty, difficulty_palette),\n",
    "         ('level', level, level_palette),\n",
    "         ('client', client, client_palette)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare(df_submissions_stats, 'raw_issues_count', attrs, range(0, 30, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare(df_submissions_stats, 'raw_issues_by_code_rows', attrs, np.arange(0, 1, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issues_stats(df: pd.DataFrame, issues: Dict[str, str], attr: str, \n",
    "                     by_type: bool = False, percent: bool = True, \n",
    "                     by_code_rows: bool = False, unique: bool = False) -> pd.DataFrame:\n",
    "    \n",
    "    issues_stats = {'issue': [], 'count': [], attr: []}\n",
    "    for v in df[attr].unique():\n",
    "        df_v = df[df[attr] == v]\n",
    "        for issue_class, issue_type in issues.items():\n",
    "            issues_stats['issue'].append(issue_type if by_type else issue_class)\n",
    "            if by_code_rows:\n",
    "                issues_stats['count'].append((df_v[issue_class] / df_v['code_rows_count']).sum())\n",
    "            elif unique:\n",
    "                issues_stats['count'].append((df_v[issue_class].apply(lambda x: min(x, 1))).sum())\n",
    "            else:\n",
    "                issues_stats['count'].append(df_v[issue_class].sum())\n",
    "            issues_stats[attr].append(v)\n",
    "    df_stats = pd.DataFrame.from_dict(issues_stats)\n",
    "    df_stats = df_stats.groupby(['issue', attr], as_index=False).sum()\n",
    "    \n",
    "    if percent:\n",
    "        count = {}\n",
    "        for v in df[attr].unique():\n",
    "            count[v] = df_stats[df_stats[attr] == v]['count'].sum()\n",
    "        df_stats['count'] = df_stats.apply(lambda x: 0 if count[x[attr]] == 0 else x['count'] / count[x[attr]], axis=1)\n",
    "    return df_stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_compare_issues(df: pd.DataFrame, attrs, issues: Dict[str, str], \n",
    "                        by_type: bool = False, percent: bool = True, by_code_rows: bool = False, n: int=20):\n",
    "    \n",
    "    n_issues = sorted(issues.keys(), key=lambda issue: -df[issue].sum())[:n]\n",
    "    \n",
    "    for attr, values, palette in attrs:\n",
    "        sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "\n",
    "        stats = get_issues_stats(df.dropna(subset=[attr]), issues, attr, by_type, percent, by_code_rows)\n",
    "        if not by_type:\n",
    "            stats = stats[stats['issue'].isin(n_issues)]\n",
    "        \n",
    "        if by_type:\n",
    "            stats.sort_values(by='count', inplace=True, ascending=False)\n",
    "        else:\n",
    "            stats.sort_values(by='issue', inplace=True, key=lambda s: [n_issues.index(issue) for issue in s])\n",
    "\n",
    "        stats.to_csv(f'new_{attr}.csv', index=False)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=((20, 10)), constrained_layout=True)\n",
    "        ax.set_xlabel('issues')\n",
    "        if by_code_rows:\n",
    "            ax.set_ylabel('Averege issues by code rows' if percent else 'Total issues by code rows')\n",
    "        else:\n",
    "            ax.set_ylabel('Percent of submissions with issue\\n' if percent else 'Total number of issues\\n in submissions')\n",
    "        if not percent:\n",
    "            ax.set_yscale('log')\n",
    "        \n",
    "        sns.lineplot(data=stats, x='issue', y='count', hue=attr, hue_order=values, ax=ax, palette=palette, marker='o')\n",
    "    \n",
    "        plt.xticks(rotation=45, ha=\"right\",rotation_mode='anchor')\n",
    "        for tick, issue in zip(ax.xaxis.get_ticklabels(), stats['issue'].unique()): \n",
    "            if (by_type and issue == 'INFO') or ((not by_type) and issues[issue] == 'INFO'):\n",
    "                tick.set_color('grey')\n",
    "            else:\n",
    "                tick.set_color('black')\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_issues_change_stats(df_all: pd.DataFrame, df_change_all: pd.DataFrame, attr, values, top_issues: List[str]):\n",
    "\n",
    "    result = {\n",
    "        attr: [],\n",
    "        'issue': [],\n",
    "        'made': [],\n",
    "        'solved': [],\n",
    "        'clean': []\n",
    "    }\n",
    "    \n",
    "    for value in values:\n",
    "        df = df_all[df_all[attr] == value]\n",
    "        df_change = df_change_all[df_change_all[attr] == value]\n",
    "        \n",
    "        for issue in top_issues:\n",
    "            clean_ids = df[df[issue] == 0]['id'].values\n",
    "\n",
    "            result[attr].append(value)\n",
    "            result['issue'].append(issue)\n",
    "            result['made'].append(df_change[df_change[issue] > 0][issue].mean())\n",
    "            result['solved'].append(df_change[df_change[issue] < 0][issue].mean())\n",
    "            df_clean = df_change[(df_change[issue] == 0) & (df_change['id'].isin(clean_ids))]\n",
    "            result['clean'].append(df_clean.shape[0] / df_change.shape[0])\n",
    "\n",
    "    return pd.DataFrame.from_dict(result)\n",
    "            \n",
    "\n",
    "\n",
    "def draw_compare_issues_change(df: pd.DataFrame, df_change: pd.DataFrame, attrs, issues: Dict[str, str], top_issues: List[str]):\n",
    "    \n",
    "    for attr, values, palette in attrs:\n",
    "        sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "            \n",
    "        stats = get_issues_change_stats(df, df_change, attr, values, top_issues)\n",
    "        \n",
    "        stats.to_csv(f'issue_change_{attr}.csv', index=False)\n",
    "                \n",
    "        for change in ['made', 'solved', 'clean']:\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=((20, 10)), constrained_layout=True)\n",
    "            ax.set_xlabel('issues')\n",
    "            ax.set_ylabel(f'Averege number of issues {change}' if change != 'clean' else f'Percent of clean solutions')\n",
    "\n",
    "            sns.lineplot(data=stats, x='issue', y=change, hue=attr, hue_order=values, ax=ax, palette=palette, marker='o')\n",
    "\n",
    "            plt.xticks(rotation=45, ha=\"right\",rotation_mode='anchor')\n",
    "            for tick, issue in zip(ax.xaxis.get_ticklabels(), top_issues): \n",
    "                if issues[issue] == 'INFO':\n",
    "                    tick.set_color('grey')\n",
    "                else:\n",
    "                    tick.set_color('black')\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_stats = pd.read_csv(raw_issues_stats_file_path)\n",
    "df_raw_issues_stats = df_raw_issues_stats[df_raw_issues_stats['id'].isin(df_submissions['id'])]\n",
    "df_raw_issues_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_stats = merge_dfs(df_raw_issues_stats, df_submissions[['id', 'step_id', 'user_id', 'client']], left_on='id', right_on='id')\n",
    "df_raw_issues_stats = merge_dfs(df_raw_issues_stats, df_steps[['id', 'complexity', 'difficulty']], left_on='step_id', right_on='id')\n",
    "df_raw_issues_stats = merge_dfs(df_raw_issues_stats, df_users[['user_id', 'level']], left_on='user_id', right_on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_classes = pd.read_csv(raw_issues_classes_file_path)\n",
    "raw_issues = {r['class']: r['type'] for i, r in df_raw_issues_classes.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_stats_unique = df_raw_issues_stats.copy()\n",
    "for issue_class, issue_type in raw_issues.items():\n",
    "    df_raw_issues_stats_unique[issue_class] = df_raw_issues_stats_unique[issue_class].apply(lambda x: min(x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of submissions with each issue class (issue classes are unique in one submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_raw_issues_stats_unique, attrs, raw_issues, by_type=False, percent=True, by_code_rows=False)\n",
    "# draw_compare_issues(df_raw_issues_stats_unique, attrs, raw_issues, by_type=True, percent=True, by_code_rows=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw issue change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_change_stats = pd.read_csv(raw_issues_change_stats_file_path)\n",
    "df_raw_issues_change_stats = df_raw_issues_change_stats[df_raw_issues_change_stats['id'].isin(df_submissions['id'])]\n",
    "df_raw_issues_change_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_change_stats = merge_dfs(df_raw_issues_change_stats, df_submissions[['id', 'step_id', 'user_id', 'client', 'attempt', 'group', 'total_attempts']], left_on='id', right_on='id')\n",
    "df_raw_issues_change_stats = merge_dfs(df_raw_issues_change_stats, df_steps[['id', 'complexity', 'difficulty']], left_on='step_id', right_on='id')\n",
    "df_raw_issues_change_stats = merge_dfs(df_raw_issues_change_stats, df_users[['user_id', 'level']], left_on='user_id', right_on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_issues = sorted(raw_issues.keys(), key=lambda issue: -df_first_attempt_stats_unique[issue].sum())[:20]\n",
    "draw_compare_issues_change(df_raw_issues_stats, df_raw_issues_change_stats, [('client', client, client_palette)], raw_issues, top_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arerage issues divided by code rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_issues_stats = merge_dfs(df_raw_issues_stats, df_submissions_stats[['id', 'code_rows_count']], left_on='id', right_on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_raw_issues_stats, attrs, raw_issues, by_type=False, percent=True, by_code_rows=True)\n",
    "# draw_compare_issues(df_raw_issues_stats, attrs, raw_issues, by_type=True, percent=True, by_code_rows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt stats\n",
    "All submissions was grouped by (user_id, step_id) and have \n",
    "* **group** - number of group and \n",
    "* **attempt** - attempt inside group\n",
    "* **total_attemps** - total number of attemps in group of submissions (size of group)\n",
    "\n",
    "First attempt submissions is when **attempt** == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats = df_submissions[df_submissions['attempt'] == 1][['id', 'user_id', 'step_id', 'client', 'attempt', 'total_attempts', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats = merge_dfs(df_first_attempt_stats, df_submissions_stats, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats_draw = df_first_attempt_stats[(df_first_attempt_stats['code_rows_count'] < 500) &\n",
    "                               (df_first_attempt_stats['code_symbols_count'] < 2000) &\n",
    "                               (df_first_attempt_stats['raw_issues_count'] < 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((25, 40)), ncols=2, nrows=5)\n",
    "\n",
    "sns.histplot(data=df_first_attempt_stats_draw, x='code_rows_count', ax=ax[0][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_first_attempt_stats_draw, x='code_symbols_count', ax=ax[0][1], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_first_attempt_stats_draw, x='raw_issues_count', ax=ax[1][0], log_scale=(False, True), bins=20)\n",
    "sns.histplot(data=df_first_attempt_stats_draw, x='qodana_issues_count', ax=ax[1][1], log_scale=(False, True), bins=20)\n",
    "sns.histplot(data=df_first_attempt_stats_draw, x='raw_issues_by_code_rows', ax=ax[2][0], log_scale=(False, True), bins=50)\n",
    "\n",
    "sns.countplot(data=df_first_attempt_stats_draw, x='difficulty', ax=ax[3][0], order=difficulty, palette=difficulty_palette)\n",
    "sns.countplot(data=df_first_attempt_stats_draw, x='complexity', ax=ax[3][1], order=complexity, palette=complexity_palette)\n",
    "sns.countplot(data=df_first_attempt_stats_draw, x='level', ax=ax[2][1], order=level, palette=level_palette)\n",
    "sns.countplot(data=df_first_attempt_stats_draw, x='client', ax=ax[4][0], order=client, palette=client_palette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_first_attempt_stats, \n",
    "                     [(('difficulty', difficulty), ('complexity', complexity)), \n",
    "                      (('level', level), ('complexity', complexity))],\n",
    "                     ['id', 'code_rows_count', 'raw_issues_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_first_attempt_stats,\n",
    "                     [(('difficulty', difficulty), ('client', client)), \n",
    "                      (('complexity', complexity), ('client', client)),\n",
    "                      (('level', level), ('client', client))],\n",
    "                     ['id', 'code_rows_count', 'raw_issues_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats = merge_dfs(df_first_attempt_stats, df_raw_issues_stats, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_attempt_stats_unique = merge_dfs(df_first_attempt_stats, df_raw_issues_stats_unique, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_first_attempt_stats_unique, attrs, raw_issues, by_type=False, percent=True)\n",
    "# draw_compare_issues(df_first_attempt_stats_unique, attrs, raw_issues, by_type=True, percent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_first_attempt_stats, attrs, raw_issues, by_type=False, percent=True, by_code_rows=True)\n",
    "draw_compare_issues(df_first_attempt_stats, attrs, raw_issues, by_type=True, percent=True, by_code_rows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last attempt stats\n",
    "\n",
    "Last attempt submissions is when **attempt** == **total_attemps** - final result of all attemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats = df_submissions[df_submissions['attempt'] == df_submissions['total_attempts']][['id', 'user_id', 'step_id', 'client', 'attempt', 'total_attempts', 'group']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats = merge_dfs(df_last_attempt_stats, df_submissions_stats, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_count = df_last_attempt_stats.shape[0]\n",
    "for attempt in range(1, 6):\n",
    "    count = df_last_attempt_stats[df_last_attempt_stats['attempt'] == attempt].shape[0]\n",
    "    persent = format(count / series_count * 100, '.2f')\n",
    "    print(f'with {attempt} attemps:', count, f'({persent}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats_draw = df_last_attempt_stats[(df_last_attempt_stats['code_rows_count'] < 500) &\n",
    "                               (df_last_attempt_stats['code_symbols_count'] < 2000) &\n",
    "                               (df_last_attempt_stats['raw_issues_count'] < 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=((25, 40)), ncols=2, nrows=5)\n",
    "\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='code_rows_count', ax=ax[0][0], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='code_symbols_count', ax=ax[0][1], log_scale=(False, True), bins=50)\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='raw_issues_count', ax=ax[1][0], log_scale=(False, True), bins=20)\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='qodana_issues_count', ax=ax[1][1], log_scale=(False, True), bins=20)\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='total_attempts', ax=ax[2][0], log_scale=(False, True), bins=5)\n",
    "sns.histplot(data=df_last_attempt_stats_draw, x='raw_issues_by_code_rows', ax=ax[2][1], log_scale=(False, True), bins=50)\n",
    "\n",
    "sns.countplot(data=df_last_attempt_stats_draw, x='difficulty', ax=ax[3][0], order=difficulty, palette=difficulty_palette)\n",
    "sns.countplot(data=df_last_attempt_stats_draw, x='complexity', ax=ax[3][1], order=complexity, palette=complexity_palette)\n",
    "sns.countplot(data=df_last_attempt_stats_draw, x='level', ax=ax[4][0], order=level, palette=level_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_last_attempt_stats, \n",
    "                     [(('difficulty', difficulty), ('complexity', complexity)), \n",
    "                      (('level', level), ('complexity', complexity))],\n",
    "                     ['total_attempts', 'code_rows_count', 'raw_issues_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_heatmap_compare(df_last_attempt_stats,\n",
    "                     [(('difficulty', difficulty), ('client', client)), \n",
    "                      (('complexity', complexity), ('client', client)),\n",
    "                      (('level', level), ('client', client))],\n",
    "                     ['total_attempts', 'code_rows_count', 'raw_issues_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats = merge_dfs(df_last_attempt_stats, df_raw_issues_stats, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats_unique = merge_dfs(df_last_attempt_stats, df_raw_issues_stats_unique, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of submissions with each issue class (issue classes are unique in one submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_last_attempt_stats_unique, attrs, raw_issues, by_type=False, percent=True)\n",
    "draw_compare_issues(df_last_attempt_stats_unique, attrs, raw_issues, by_type=True, percent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arerage issues by code rows density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_compare_issues(df_last_attempt_stats, attrs, raw_issues, by_type=False, percent=True, by_code_rows=True)\n",
    "# draw_compare_issues(df_last_attempt_stats, attrs, raw_issues, by_type=True, percent=True, by_code_rows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client_stats = pd.read_csv('../data/java/result_submissions_client_stats_java11.csv')\n",
    "df_client_stats['client_series'] = df_client_stats['client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats = merge_dfs(df_last_attempt_stats, df_client_stats, left_on='group', right_on='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_attempt_stats[['client_series']].value_counts(ascending=False).to_csv('client_stats_java.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_client_dynamic(attemps: int):\n",
    "    sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 10})\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), constrained_layout=True)\n",
    "    plt.xticks(rotation=45, ha=\"right\",rotation_mode='anchor')\n",
    "\n",
    "    df = df_last_attempt_stats[df_last_attempt_stats['total_attempts'] == attemps]\n",
    "    sns.countplot(data=df, ax=ax, x='client_series', order=df['client_series'].value_counts(ascending=False).index, color='grey')\n",
    "    ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "client_stats = df_last_attempt_stats['client_series'].value_counts()\n",
    "attepmt_clients = [{c_from: {c_to: 0 for c_to in client} for c_from in client} \n",
    "                   for _ in range(MAX_TOTAL_ATTEMPTS)]\n",
    "\n",
    "for key in client_stats.keys():\n",
    "    client_chain = ast.literal_eval(key)\n",
    "    for i in range(1, len(client_chain)):\n",
    "        attepmt_clients[i - 1][client_chain[i - 1]][client_chain[i]] += client_stats[key] \n",
    "        \n",
    "attepmt_clients_values = []\n",
    "for i in range(MAX_TOTAL_ATTEMPTS - 1):\n",
    "    for c_from in client:\n",
    "        for c_to in client:\n",
    "            attepmt_clients_values.append(attepmt_clients[i][c_from][c_to])\n",
    "attepmt_clients_values = sorted(attepmt_clients_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph):\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    pos = nx.get_node_attributes(G,'pos')\n",
    "    width = [G[u][v]['width'] for u, v in graph.edges()]\n",
    "    labels = nx.get_edge_attributes(graph, 'weight')\n",
    "    nx.draw(graph, pos, with_labels=True, edge_color='black', font_color='white', node_size=1500, width=width)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attepmt_clients_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attepmt_client_dict = {\"attempt\": [], \"from\": [], \"to\": [], \"count\": []}\n",
    "for i in range(0, 5):\n",
    "    for from_client in client:\n",
    "        for to_client in client:\n",
    "            attepmt_client_dict['attempt'].append(i + 1)\n",
    "            attepmt_client_dict['from'].append(from_client)\n",
    "            attepmt_client_dict['to'].append(to_client)\n",
    "            print(attepmt_clients_values[i])\n",
    "            attepmt_client_dict['count'].append(attepmt_clients_values[i][from_client][to_client])\n",
    "pd.DataFrame.from_dict(attepmt_client_dict).to_csv('attepmt_client_stats_java.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "     \n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(MAX_TOTAL_ATTEMPTS):\n",
    "    for j, c in enumerate(client):\n",
    "        G.add_node(f'{c}_{i + 1}', pos=(i + (0 if j % 2 == 0 and i % 2 == 0 else 0.3), j))\n",
    "\n",
    "for i in range(MAX_TOTAL_ATTEMPTS - 1):\n",
    "    for c_from in client:\n",
    "        for c_to in client:\n",
    "            weight = attepmt_clients[i][c_from][c_to]\n",
    "            width = attepmt_clients_values.index(weight)\n",
    "            G.add_edge(f'{c_from}_{i + 1}', f'{c_to}_{i + 2}', \n",
    "                       weight=weight,\n",
    "                       width=(width + 5) / 2\n",
    "                      )\n",
    "\n",
    "draw_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_client_dynamic(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission series (groups)\n",
    "To pass the step user can make several attemps. The ordered sequence of attemps in **submission series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_series_stats = merge_dfs(df_submissions_stats, df_submissions[['id', 'user_id', 'step_id', 'client', 'attempt', 'total_attempts', 'group']], left_on='id', right_on='id')\n",
    "df_submissions_series_stats = df_submissions_series_stats[df_submissions_series_stats['total_attempts'] < 6]\n",
    "df_submissions_series_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_series_stats = merge_dfs(df_submissions_series_stats, df_steps[['id', 'complexity', 'difficulty', 'template']], left_on=\"step_id\", right_on=\"id\")\n",
    "df_submissions_series_stats = merge_dfs(df_submissions_series_stats, df_users[['user_id', 'level']], left_on=\"user_id\", right_on=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def get_submissions_series_dynamic(df: pd.DataFrame, features: List[str], is_mean=False):\n",
    "    series_stats_dict = {\n",
    "        'attempt': [],\n",
    "        'count': [], \n",
    "    }\n",
    "    for f in features:\n",
    "        series_stats_dict[f] = []\n",
    "        \n",
    "    for attempt in df['attempt'].unique():\n",
    "        df_a = df[df['attempt'] == attempt]\n",
    "        series_stats_dict['attempt'].append(attempt)\n",
    "        series_stats_dict['count'].append(df_a.shape[0])\n",
    "        for f in features:\n",
    "            series_stats_dict[f].append(df_a[f])\n",
    "    if is_mean:\n",
    "        for f in features:\n",
    "            series_stats_dict[f] = list(map(np.mean, series_stats_dict[f]))\n",
    "    else:\n",
    "        for f in features:\n",
    "            series_stats_dict[f] = list(map(np.median, series_stats_dict[f]))\n",
    "    return pd.DataFrame.from_dict(series_stats_dict)\n",
    "\n",
    "def draw_submissions_series_dynamic(df: pd.DataFrame, attrs, features, max_attemps: int = 10, is_eq=False, is_mean=False):\n",
    "    if not is_eq:\n",
    "        df = df[df['total_attempts'] <= max_attemps].copy()\n",
    "    else:\n",
    "        df = df[df['total_attempts'] == max_attemps].copy()\n",
    "\n",
    "    for attr, values, palette in attrs:\n",
    "        sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "        fig, ax = plt.subplots(figsize=((20, 6 * len(features))), nrows=len(features), constrained_layout=True)\n",
    "        for v in values:\n",
    "            df_dynamic = get_submissions_series_dynamic(df[df[attr] == v], features, is_mean)\n",
    "            df_dynamic.sort_values(['attempt'])\n",
    "\n",
    "            for i, feature in enumerate(features):\n",
    "                axi = ax if len(features) == 1 else ax[i]\n",
    "                sns.lineplot(data=df_dynamic, x='attempt', y=feature, ax=axi, label=v, marker='o', color=palette[v])\n",
    "                axi.set_title(f'Mean {feature} by attempt' if is_mean else f'Median {feature} by attempt')\n",
    "                axi.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['raw_issues_count', 'raw_issues_by_code_rows']\n",
    "attemps = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions series dynamic\n",
    "Plots show how average soution parameters change throught attemps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamin for all sobmission series with total_attemps = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_submissions_series_dynamic(df_submissions_series_stats, attrs, features, attemps, is_eq=False, is_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submissions_issues_dynamic(df: pd.DataFrame, issues, by_type=True, is_mean=False):\n",
    "    series_stats_dict = {\n",
    "        'attempt': [],\n",
    "        'count': [], \n",
    "    }\n",
    "    for issues_class, issues_type in issues.items():\n",
    "        series_stats_dict[issues_type if by_type else issues_class] = []\n",
    "    for attempt in df['attempt'].unique():\n",
    "        df_a = df[df['attempt'] == attempt]\n",
    "        series_stats_dict['attempt'].append(attempt)\n",
    "        series_stats_dict['count'].append(df_a.shape[0])\n",
    "        if by_type:\n",
    "            for issue_type in set(issues.values()):\n",
    "                series_stats_dict[issue_type].append(np.zeros(df_a.shape[0]))\n",
    "        else:\n",
    "            for issue_class in set(issues.keys()):\n",
    "                series_stats_dict[issue_class].append(np.zeros(df_a.shape[0]))\n",
    "        for issues_class, issues_type in issues.items():\n",
    "            series_stats_dict[issues_type if by_type else issues_class][-1] += df_a[issues_class]\n",
    "    for issues_class, issues_type in issues.items():\n",
    "        issue = issues_type if by_type else issues_class\n",
    "        if is_mean:\n",
    "            series_stats_dict[issue] = list(map(np.mean, series_stats_dict[issue]))\n",
    "        else:\n",
    "            series_stats_dict[issue] = list(map(np.median, series_stats_dict[issue]))\n",
    "    return pd.DataFrame.from_dict(series_stats_dict)\n",
    "\n",
    "def draw_submissions_issues_dynamic(df: pd.DataFrame, issues, max_attemps: int = 10, by_type=True, \n",
    "                                    is_eq=False, is_mean=False, bias=0.01):\n",
    "    if not is_eq:\n",
    "        df = df[df['total_attempts'] <= max_attemps].copy()\n",
    "    else:\n",
    "        df = df[df['total_attempts'] == max_attemps].copy()\n",
    "\n",
    "    df_dynamic = get_submissions_issues_dynamic(df, issues, by_type, is_mean)\n",
    "    fig, ax = plt.subplots(figsize=((20, 10)))\n",
    "    sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "    \n",
    "    df_dynamic.to_csv('issues_dynamic_java.csv', index=False)\n",
    "    issues = set(issues.values()) if by_type else set(issues.keys())\n",
    "    for issue in issues:\n",
    "        if (df_dynamic[issue] > bias).any():\n",
    "            sns.lineplot(data=df_dynamic, x='attempt', y=issue, ax=ax, label=issue, marker='o')\n",
    "    ax.set_title('Mean number of issues by attemps' if is_mean else 'Median number of issues by attemps')\n",
    "    ax.set_ylabel('Number of issues')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"lower center\", bbox_to_anchor=[0.5, -0.15],\n",
    "                       ncol=3, shadow=True, fancybox=True)\n",
    "    ax.get_legend().remove()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_series_issues_stats = merge_dfs(df_submissions_series_stats, df_raw_issues_stats, left_on='id', right_on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_submissions_issues_dynamic(df_submissions_series_issues_stats, raw_issues, 3, \n",
    "                                by_type=False, is_eq=True, is_mean=True, bias=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_submissions_issues_dynamic(df_submissions_series_issues_stats, raw_issues, attemps, \n",
    "                                by_type=True, is_eq=False, is_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_submissions_issues_dynamic_all(df: pd.DataFrame, issues, max_attemps: int = 10, by_type=True, is_mean=False):\n",
    "    nrows, ncols = max_attemps // 2, 2\n",
    "    fig, ax = plt.subplots(figsize=((20, 12)), nrows=nrows, ncols=ncols, sharey=True, constrained_layout=True)\n",
    "    sns.set_theme(style='whitegrid', font_scale=2, rc={\"lines.linewidth\": 5, \"lines.markersize\": 15})\n",
    "    issues_values = set(issues.values()) if by_type else set(issues.keys())\n",
    "    \n",
    "    for a in range(2, max_attemps + 1):\n",
    "        df_dynamic = get_submissions_issues_dynamic(df[df['total_attempts'] == a], issues, by_type, is_mean)  \n",
    "        i, j = (a - 2) // 2, a % 2\n",
    "        for issue in issues_values:\n",
    "            if (df_dynamic[issue] > 0.1).any():\n",
    "                sns.lineplot(data=df_dynamic, x='attempt', y=issue, ax=ax[i][j], label=issue, marker='o')\n",
    "        ax[i][j].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax[i][j].set_title(f'total_attempts={a}')\n",
    "        ax[i][j].set_ylabel('')\n",
    "        ax[i][j].set_xlabel('')\n",
    "        if i == 0 or j == 0:\n",
    "            handles, labels = ax[i][j].get_legend_handles_labels()\n",
    "            fig.legend(handles, labels, loc=\"lower center\", bbox_to_anchor=[0.5, -0.1],\n",
    "                       ncol=5, shadow=True, fancybox=True)\n",
    "        ax[i][j].get_legend().remove()\n",
    "    fig.text(0.5, -0.02, 'Attemps', ha='center')\n",
    "    fig.text(-0.02, 0.5, 'Percent of submission', va='center', rotation='vertical')\n",
    "    fig.suptitle('Percent of submission series with issue at each attempt')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions_series_issues_stats = merge_dfs(df_submissions_series_stats, df_raw_issues_stats_unique, left_on='id', right_on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draw_submissions_issues_dynamic_all(df_submissions_series_issues_stats, raw_issues, 5, \n",
    "                                    by_type=False, is_mean=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
